torch>=2.0.0
numpy>=1.22.0
faiss-gpu # Or faiss-cpu if you don't have a CUDA-enabled GPU
sentence-transformers>=2.2.2
datasets>=2.10.0
transformers>=4.30.0
peft>=0.5.0
bitsandbytes>=0.39.0
accelerate>=0.20.0
flask>=2.0.0
requests>=2.28.0
tqdm>=4.65.0
ninja # For faster PyTorch JIT compilation
triton # For PyTorch inductor
safetensors # For faster model loading
xformers # For memory efficient attention if using GPU
optimum # Hugging Face's optimization toolkit